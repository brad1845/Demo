import {
  Observable
} from "./chunk-2YUEJ7I2.js";
import {
  Logger
} from "./chunk-J4DZ2XK7.js";

// node_modules/@babylonjs/core/AudioV2/audioUtils.js
var _FileExtensionRegex = new RegExp("\\.(\\w{3,4})($|\\?)");
var CurveLength = 100;
var TmpLineValues = new Float32Array([0, 0]);
var TmpCurveValues = null;
var ExpCurve = null;
var LogCurve = null;
function GetExpCurve() {
  if (!ExpCurve) {
    ExpCurve = new Float32Array(CurveLength);
    const increment = 1 / (CurveLength - 1);
    let x = increment;
    for (let i = 1; i < CurveLength; i++) {
      ExpCurve[i] = Math.exp(-11.512925464970227 * (1 - x));
      x += increment;
    }
  }
  return ExpCurve;
}
function GetLogCurve() {
  if (!LogCurve) {
    LogCurve = new Float32Array(CurveLength);
    const increment = 1 / CurveLength;
    let x = increment;
    for (let i = 0; i < CurveLength; i++) {
      LogCurve[i] = 1 + Math.log10(x) / Math.log10(CurveLength);
      x += increment;
    }
  }
  return LogCurve;
}
function _GetAudioParamCurveValues(shape, from, to) {
  if (!TmpCurveValues) {
    TmpCurveValues = new Float32Array(CurveLength);
  }
  let normalizedCurve;
  if (shape === "linear") {
    TmpLineValues[0] = from;
    TmpLineValues[1] = to;
    return TmpLineValues;
  } else if (shape === "exponential") {
    normalizedCurve = GetExpCurve();
  } else if (shape === "logarithmic") {
    normalizedCurve = GetLogCurve();
  } else {
    throw new Error(`Unknown ramp shape: ${shape}`);
  }
  const direction = Math.sign(to - from);
  const range = Math.abs(to - from);
  if (direction === 1) {
    for (let i = 0; i < normalizedCurve.length; i++) {
      TmpCurveValues[i] = from + range * normalizedCurve[i];
    }
  } else {
    let j = CurveLength - 1;
    for (let i = 0; i < normalizedCurve.length; i++, j--) {
      TmpCurveValues[i] = from - range * (1 - normalizedCurve[j]);
    }
  }
  return TmpCurveValues;
}
function _CleanUrl(url) {
  return url.replace(/#/gm, "%23");
}

// node_modules/@babylonjs/core/AudioV2/webAudio/components/webAudioParameterComponent.js
var MaxWaitTime = 0.011;
var MinRampDuration = 1e-6;
var _WebAudioParameterComponent = class {
  /** @internal */
  constructor(engine, param) {
    this._deferredRampOptions = {
      duration: 0,
      shape: "linear"
    };
    this._deferredTargetValue = -1;
    this._isObservingUpdates = false;
    this._rampEndTime = 0;
    this._applyDeferredRamp = () => {
      if (0 < this._deferredRampOptions.duration && this._rampEndTime < this._engine.currentTime) {
        this.setTargetValue(this._deferredTargetValue, this._deferredRampOptions);
      }
    };
    this._engine = engine;
    this._param = param;
    this._targetValue = param.value;
  }
  /** @internal */
  get isRamping() {
    return this._engine.currentTime < this._rampEndTime;
  }
  /** @internal */
  get targetValue() {
    return this._targetValue;
  }
  set targetValue(value) {
    this.setTargetValue(value);
  }
  /** @internal */
  get value() {
    return this._param.value;
  }
  /** @internal */
  dispose() {
    this._clearDeferredRamp();
    this._param = null;
    this._engine = null;
  }
  /**
   * Sets the target value of the audio parameter with an optional ramping duration and shape.
   *
   * If a ramp is close to finishing, it will wait for the ramp to finish before setting the new value; otherwise it
   * will throw an error because of a bug in Firefox that prevents active ramps from being cancelled with
   * `cancelScheduledValues`. See https://bugzilla.mozilla.org/show_bug.cgi?id=1752775. Other browsers do not have
   * this issue, but we throw an error in all browsers to ensure consistent behavior.
   *
   * There are other similar WebAudio APIs for ramping parameters, (e.g. `linearRampToValueAtTime` and
   * `exponentialRampToValueAtTime`) but they don't work in Firefox and Meta Quest Chrome.
   *
   * It may be better in the long run to implement our own ramping logic with a WASM audio worklet instead of using
   * `setValueCurveAtTime`. Another alternative is to use `setValueAtTime` wtih a custom shape, but that will
   * probably be a performance hit to maintain quality at audio rates.
   *
   * @internal
   */
  setTargetValue(value, options = null) {
    if (this._targetValue === value) {
      return;
    }
    const shape = typeof options?.shape === "string" ? options.shape : "linear";
    let duration = typeof options?.duration === "number" ? Math.max(options.duration, this._engine.parameterRampDuration) : this._engine.parameterRampDuration;
    const startTime = this._engine.currentTime;
    if (startTime < this._rampEndTime) {
      const timeLeft = this._rampEndTime - startTime;
      if (MaxWaitTime < timeLeft) {
        throw new Error("Audio parameter not set. Wait for current ramp to finish.");
      } else {
        this._deferRamp(value, duration, shape);
        return;
      }
    }
    if ((duration = Math.max(this._engine.parameterRampDuration, duration)) < MinRampDuration) {
      this._param.setValueAtTime(this._targetValue = value, startTime);
      return;
    }
    this._param.cancelScheduledValues(startTime);
    this._param.setValueCurveAtTime(_GetAudioParamCurveValues(shape, this._targetValue, this._targetValue = value), startTime, duration);
    this._clearDeferredRamp();
    this._rampEndTime = startTime + duration;
  }
  _deferRamp(value, duration, shape) {
    this._deferredRampOptions.duration = duration;
    this._deferredRampOptions.shape = shape;
    this._deferredTargetValue = value;
    if (!this._isObservingUpdates) {
      this._engine._addUpdateObserver(this._applyDeferredRamp);
      this._isObservingUpdates = true;
    }
  }
  _clearDeferredRamp() {
    this._deferredRampOptions.duration = 0;
    if (this._isObservingUpdates) {
      this._engine._removeUpdateObserver(this._applyDeferredRamp);
      this._isObservingUpdates = false;
    }
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/abstractAudioNode.js
var AudioNodeType;
(function(AudioNodeType2) {
  AudioNodeType2[AudioNodeType2["HAS_INPUTS"] = 1] = "HAS_INPUTS";
  AudioNodeType2[AudioNodeType2["HAS_OUTPUTS"] = 2] = "HAS_OUTPUTS";
  AudioNodeType2[AudioNodeType2["HAS_INPUTS_AND_OUTPUTS"] = 3] = "HAS_INPUTS_AND_OUTPUTS";
})(AudioNodeType || (AudioNodeType = {}));
var AbstractAudioNode = class {
  constructor(engine, nodeType) {
    this.onDisposeObservable = new Observable();
    this.engine = engine;
    if (nodeType & 1) {
      this._upstreamNodes = /* @__PURE__ */ new Set();
    }
    if (nodeType & 2) {
      this._downstreamNodes = /* @__PURE__ */ new Set();
    }
  }
  /**
   * Releases associated resources.
   * - Triggers `onDisposeObservable`.
   * @see {@link onDisposeObservable}
   */
  dispose() {
    if (this._downstreamNodes) {
      for (const node of Array.from(this._downstreamNodes)) {
        if (!this._disconnect(node)) {
          throw new Error("Disconnect failed");
        }
      }
      this._downstreamNodes.clear();
    }
    if (this._upstreamNodes) {
      for (const node of Array.from(this._upstreamNodes)) {
        if (!node._disconnect(this)) {
          throw new Error("Disconnect failed");
        }
      }
      this._upstreamNodes.clear();
    }
    this.onDisposeObservable.notifyObservers(this);
    this.onDisposeObservable.clear();
  }
  /**
   * Connect to a downstream audio input node.
   * @param node - The downstream audio input node to connect
   * @returns `true` if the node is successfully connected; otherwise `false`
   */
  _connect(node) {
    if (!this._downstreamNodes) {
      return false;
    }
    if (this._downstreamNodes.has(node)) {
      return false;
    }
    if (!node._onConnect(this)) {
      return false;
    }
    this._downstreamNodes.add(node);
    return true;
  }
  /**
   * Disconnects a downstream audio input node.
   * @param node - The downstream audio input node to disconnect
   * @returns `true` if the node is successfully disconnected; otherwise `false`
   */
  _disconnect(node) {
    if (!this._downstreamNodes) {
      return false;
    }
    if (!this._downstreamNodes.delete(node)) {
      return false;
    }
    return node._onDisconnect(this);
  }
  /**
   * Called when an upstream audio output node is connecting.
   * @param node - The connecting upstream audio node
   * @returns `true` if the node is successfully connected; otherwise `false`
   */
  _onConnect(node) {
    if (!this._upstreamNodes) {
      return false;
    }
    if (this._upstreamNodes.has(node)) {
      return false;
    }
    this._upstreamNodes.add(node);
    return true;
  }
  /**
   * Called when an upstream audio output node disconnects.
   * @param node - The disconnecting upstream audio node
   * @returns `true` if node is sucessfully disconnected; otherwise `false`
   */
  _onDisconnect(node) {
    return this._upstreamNodes?.delete(node) ?? false;
  }
};
var AbstractNamedAudioNode = class extends AbstractAudioNode {
  constructor(name, engine, nodeType) {
    super(engine, nodeType);
    this.onNameChangedObservable = new Observable();
    this._name = name;
  }
  /**
   * The name of the audio node.
   * - Triggers `onNameChangedObservable` when changed.
   * @see {@link onNameChangedObservable}
   */
  get name() {
    return this._name;
  }
  set name(newName) {
    if (this._name === newName) {
      return;
    }
    const oldName = this._name;
    this._name = newName;
    this.onNameChangedObservable.notifyObservers({ newName, oldName, node: this });
  }
  dispose() {
    super.dispose();
    this.onNameChangedObservable.clear();
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/abstractAudioAnalyzer.js
var _AudioAnalyzerDefaults = {
  fftSize: 2048,
  minDecibels: -100,
  maxDecibels: -30,
  smoothing: 0.8
};
function _HasAudioAnalyzerOptions(options) {
  return options.analyzerEnabled || options.analyzerFFTSize !== void 0 || options.analyzerMinDecibels !== void 0 || options.analyzerMaxDecibels !== void 0 || options.analyzerSmoothing !== void 0;
}
var AbstractAudioAnalyzer = class {
  /**
   * The number of data values that will be returned when calling getByteFrequencyData() or getFloatFrequencyData(). This is always half the `fftSize`.
   */
  get frequencyBinCount() {
    return this.fftSize / 2;
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subNodes/abstractAudioSubNode.js
var _AbstractAudioSubNode = class extends AbstractNamedAudioNode {
  /** @internal */
  constructor(name, engine) {
    super(
      name,
      engine,
      3
      /* AudioNodeType.HAS_INPUTS_AND_OUTPUTS */
    );
  }
  /** @internal */
  connect(node) {
    if (!this._connect(node)) {
      throw new Error("Connect failed");
    }
  }
  /** @internal */
  disconnect(node) {
    if (!this._disconnect(node)) {
      throw new Error("Disconnect failed");
    }
  }
  /** @internal */
  disconnectAll() {
    if (!this._downstreamNodes) {
      throw new Error("Disconnect failed");
    }
    const it = this._downstreamNodes.values();
    for (let next = it.next(); !next.done; next = it.next()) {
      if (!this._disconnect(next.value)) {
        throw new Error("Disconnect failed");
      }
    }
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subNodes/volumeAudioSubNode.js
var _VolumeAudioDefaults = {
  volume: 1
};
var _VolumeAudioSubNode = class extends _AbstractAudioSubNode {
  constructor(engine) {
    super("Volume", engine);
  }
  /** @internal */
  setOptions(options) {
    this.volume = options.volume ?? _VolumeAudioDefaults.volume;
  }
};
function _GetVolumeAudioSubNode(subGraph) {
  return subGraph.getSubNode(
    "Volume"
    /* AudioSubNode.VOLUME */
  );
}
function _GetVolumeAudioProperty(subGraph, property) {
  return _GetVolumeAudioSubNode(subGraph)?.[property] ?? _VolumeAudioDefaults[property];
}

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subNodes/audioAnalyzerSubNode.js
var _AudioAnalyzerSubNode = class extends _AbstractAudioSubNode {
  constructor(engine) {
    super("Analyzer", engine);
  }
  /** @internal */
  setOptions(options) {
    this.fftSize = options.analyzerFFTSize ?? _AudioAnalyzerDefaults.fftSize;
    this.minDecibels = options.analyzerMinDecibels ?? _AudioAnalyzerDefaults.minDecibels;
    this.maxDecibels = options.analyzerMaxDecibels ?? _AudioAnalyzerDefaults.maxDecibels;
    this.smoothing = options.analyzerSmoothing ?? _AudioAnalyzerDefaults.smoothing;
  }
};
function _GetAudioAnalyzerSubNode(subGraph) {
  return subGraph.getSubNode(
    "Analyzer"
    /* AudioSubNode.ANALYZER */
  );
}
function _SetAudioAnalyzerProperty(subGraph, property, value) {
  subGraph.callOnSubNode("Analyzer", (node) => {
    node[property] = value;
  });
}

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subProperties/audioAnalyzer.js
var EmptyByteFrequencyData = null;
var EmptyFloatFrequencyData = null;
function _GetEmptyByteFrequencyData() {
  if (!EmptyByteFrequencyData) {
    EmptyByteFrequencyData = new Uint8Array();
  }
  return EmptyByteFrequencyData;
}
function _GetEmptyFloatFrequencyData() {
  if (!EmptyFloatFrequencyData) {
    EmptyFloatFrequencyData = new Float32Array();
  }
  return EmptyFloatFrequencyData;
}
var _AudioAnalyzer = class extends AbstractAudioAnalyzer {
  /** @internal */
  constructor(subGraph) {
    super();
    this._fftSize = _AudioAnalyzerDefaults.fftSize;
    this._maxDecibels = _AudioAnalyzerDefaults.maxDecibels;
    this._minDecibels = _AudioAnalyzerDefaults.minDecibels;
    this._smoothing = _AudioAnalyzerDefaults.smoothing;
    this._subGraph = subGraph;
  }
  /** @internal */
  get fftSize() {
    return this._fftSize;
  }
  set fftSize(value) {
    this._fftSize = value;
    _SetAudioAnalyzerProperty(this._subGraph, "fftSize", value);
  }
  /** @internal */
  get isEnabled() {
    return _GetAudioAnalyzerSubNode(this._subGraph) !== null;
  }
  /** @internal */
  get minDecibels() {
    return this._minDecibels;
  }
  set minDecibels(value) {
    this._minDecibels = value;
    _SetAudioAnalyzerProperty(this._subGraph, "minDecibels", value);
  }
  /** @internal */
  get maxDecibels() {
    return this._maxDecibels;
  }
  set maxDecibels(value) {
    this._maxDecibels = value;
    _SetAudioAnalyzerProperty(this._subGraph, "maxDecibels", value);
  }
  /** @internal */
  get smoothing() {
    return this._smoothing;
  }
  set smoothing(value) {
    this._smoothing = value;
    _SetAudioAnalyzerProperty(this._subGraph, "smoothing", value);
  }
  /** @internal */
  dispose() {
    const subNode = _GetAudioAnalyzerSubNode(this._subGraph);
    if (subNode) {
      this._subGraph.removeSubNodeAsync(subNode);
      subNode.dispose();
    }
  }
  /** @internal */
  async enableAsync() {
    const subNode = _GetAudioAnalyzerSubNode(this._subGraph);
    if (!subNode) {
      await this._subGraph.createAndAddSubNodeAsync(
        "Analyzer"
        /* AudioSubNode.ANALYZER */
      );
    }
  }
  /** @internal */
  getByteFrequencyData() {
    const subNode = _GetAudioAnalyzerSubNode(this._subGraph);
    if (!subNode) {
      Logger.Warn("AudioAnalyzer not enabled");
      this.enableAsync();
      return _GetEmptyByteFrequencyData();
    }
    return subNode.getByteFrequencyData();
  }
  /** @internal */
  getFloatFrequencyData() {
    const subNode = _GetAudioAnalyzerSubNode(this._subGraph);
    if (!subNode) {
      Logger.Warn("AudioAnalyzer not enabled");
      this.enableAsync();
      return _GetEmptyFloatFrequencyData();
    }
    return subNode.getFloatFrequencyData();
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/abstractAudioOutNode.js
var AbstractAudioOutNode = class extends AbstractNamedAudioNode {
  constructor(name, engine, nodeType) {
    super(name, engine, nodeType);
    this._analyzer = null;
  }
  /**
   * The analyzer features of the bus.
   */
  get analyzer() {
    return this._analyzer ?? (this._analyzer = new _AudioAnalyzer(this._subGraph));
  }
  /**
   * The audio output volume.
   */
  get volume() {
    return _GetVolumeAudioProperty(this._subGraph, "volume");
  }
  set volume(value) {
    const node = _GetVolumeAudioSubNode(this._subGraph);
    if (!node) {
      throw new Error("No volume subnode");
    }
    node.volume = value;
  }
  /**
   * Releases associated resources.
   */
  dispose() {
    super.dispose();
    this._analyzer?.dispose();
    this._analyzer = null;
    this._subGraph.dispose();
  }
  /**
   * Sets the audio output volume with optional ramping.
   * If the duration is 0 then the volume is set immediately, otherwise it is ramped to the new value over the given duration using the given shape.
   * If a ramp is already in progress then the volume is not set and an error is thrown.
   * @param value The value to set the volume to.
   * @param options The options to use for ramping the volume change.
   */
  setVolume(value, options = null) {
    const node = _GetVolumeAudioSubNode(this._subGraph);
    if (!node) {
      throw new Error("No volume subnode");
    }
    node.setVolume(value, options);
  }
};

// node_modules/@babylonjs/core/AudioV2/abstractAudio/subNodes/abstractAudioSubGraph.js
var _AbstractAudioSubGraph = class {
  constructor() {
    this._createSubNodePromises = {};
    this._isDisposed = false;
    this._subNodes = {};
    this._onSubNodeDisposed = (node) => {
      const subNode = node;
      delete this._subNodes[subNode.name];
      this._onSubNodesChanged();
    };
  }
  /**
   * Executes the given callback with the named sub node, creating the sub node if needed.
   *
   * @param name The name of the sub node
   * @param callback The function to call with the named sub node
   *
   * @internal
   */
  callOnSubNode(name, callback) {
    const node = this.getSubNode(name);
    if (node) {
      callback(node);
      return;
    }
    this._createSubNodePromisesResolvedAsync().then(() => {
      const node2 = this.getSubNode(name);
      if (node2) {
        callback(node2);
        return;
      }
      this.createAndAddSubNodeAsync(name).then((node3) => {
        callback(node3);
      });
    });
  }
  /**
   * Creates the named subnode and adds it to the sub graph.
   *
   * @param name The name of the sub node.
   * @returns A promise that resolves to the created sub node.
   *
   * @internal
   */
  // eslint-disable-next-line @typescript-eslint/promise-function-async, no-restricted-syntax
  createAndAddSubNodeAsync(name) {
    var _a;
    (_a = this._createSubNodePromises)[name] || (_a[name] = this._createSubNode(name).then((node) => {
      this._addSubNode(node);
      return node;
    }));
    return this._createSubNodePromises[name];
  }
  /**
   * Releases associated resources.
   *
   * @internal
   */
  dispose() {
    this._isDisposed = true;
    const subNodes = Object.values(this._subNodes);
    for (const subNode of subNodes) {
      subNode.dispose();
    }
    this._subNodes = {};
    this._createSubNodePromises = {};
  }
  /**
   * Gets a previously created sub node.
   *
   * @param name - The name of the sub node
   * @returns The named sub node, or `null` if it has not been created, yet
   *
   * @internal
   * */
  getSubNode(name) {
    return this._subNodes[name] ?? null;
  }
  /**
   * Removes a sub node from the sub graph.
   *
   * @param subNode - The sub node to remove
   * @returns A promise that resolves when the sub node is removed
   *
   * @internal
   */
  async removeSubNodeAsync(subNode) {
    await this._createSubNodePromisesResolvedAsync();
    const name = subNode.name;
    if (this._subNodes[name]) {
      delete this._subNodes[name];
    }
    delete this._createSubNodePromises[name];
    this._onSubNodesChanged();
  }
  async _createSubNodePromisesResolvedAsync() {
    return await Promise.all(Object.values(this._createSubNodePromises));
  }
  _addSubNode(node) {
    if (this._isDisposed) {
      node.dispose();
      return;
    }
    this._subNodes[node.name] = node;
    node.onDisposeObservable.addOnce(this._onSubNodeDisposed);
    this._onSubNodesChanged();
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/subNodes/volumeWebAudioSubNode.js
async function _CreateVolumeAudioSubNodeAsync(engine) {
  return new _VolumeWebAudioSubNode(engine);
}
var _VolumeWebAudioSubNode = class extends _VolumeAudioSubNode {
  /** @internal */
  constructor(engine) {
    super(engine);
    const gainNode = this.node = new GainNode(engine._audioContext);
    this._volume = new _WebAudioParameterComponent(engine, gainNode.gain);
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._volume.dispose();
  }
  /** @internal */
  get volume() {
    return this._volume.value;
  }
  /** @internal */
  set volume(value) {
    this.setVolume(value);
  }
  /** @internal */
  get _inNode() {
    return this.node;
  }
  /** @internal */
  get _outNode() {
    return this.node;
  }
  /** @internal */
  setVolume(value, options = null) {
    this._volume.setTargetValue(value, options);
  }
  _connect(node) {
    const connected = super._connect(node);
    if (!connected) {
      return false;
    }
    if (node._inNode) {
      this.node.connect(node._inNode);
    }
    return true;
  }
  _disconnect(node) {
    const disconnected = super._disconnect(node);
    if (!disconnected) {
      return false;
    }
    if (node._inNode) {
      this.node.disconnect(node._inNode);
    }
    return true;
  }
  /** @internal */
  getClassName() {
    return "_VolumeWebAudioSubNode";
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/subNodes/webAudioAnalyzerSubNode.js
async function _CreateAudioAnalyzerSubNodeAsync(engine) {
  return new _WebAudioAnalyzerSubNode(engine);
}
var _WebAudioAnalyzerSubNode = class extends _AudioAnalyzerSubNode {
  /** @internal */
  constructor(engine) {
    super(engine);
    this._byteFrequencyData = null;
    this._floatFrequencyData = null;
    this._analyzerNode = new AnalyserNode(engine._audioContext);
  }
  /** @internal */
  get fftSize() {
    return this._analyzerNode.fftSize;
  }
  set fftSize(value) {
    if (value === this._analyzerNode.fftSize) {
      return;
    }
    this._analyzerNode.fftSize = value;
    this._clearArrays();
  }
  /** @internal */
  get _inNode() {
    return this._analyzerNode;
  }
  /** @internal */
  get minDecibels() {
    return this._analyzerNode.minDecibels;
  }
  set minDecibels(value) {
    this._analyzerNode.minDecibels = value;
  }
  /** @internal */
  get maxDecibels() {
    return this._analyzerNode.maxDecibels;
  }
  set maxDecibels(value) {
    this._analyzerNode.maxDecibels = value;
  }
  /** @internal */
  get smoothing() {
    return this._analyzerNode.smoothingTimeConstant;
  }
  set smoothing(value) {
    this._analyzerNode.smoothingTimeConstant = value;
  }
  /** @internal */
  dispose() {
    super.dispose();
    this._clearArrays();
    this._byteFrequencyData = null;
    this._floatFrequencyData = null;
    this._analyzerNode.disconnect();
  }
  /** @internal */
  getClassName() {
    return "_WebAudioAnalyzerSubNode";
  }
  /** @internal */
  getByteFrequencyData() {
    if (!this._byteFrequencyData || this._byteFrequencyData.length === 0) {
      this._byteFrequencyData = new Uint8Array(this._analyzerNode.frequencyBinCount);
    }
    this._analyzerNode.getByteFrequencyData(this._byteFrequencyData);
    return this._byteFrequencyData;
  }
  /** @internal */
  getFloatFrequencyData() {
    if (!this._floatFrequencyData || this._floatFrequencyData.length === 0) {
      this._floatFrequencyData = new Float32Array(this._analyzerNode.frequencyBinCount);
    }
    this._analyzerNode.getFloatFrequencyData(this._floatFrequencyData);
    return this._floatFrequencyData;
  }
  _clearArrays() {
    this._byteFrequencyData?.set(_GetEmptyByteFrequencyData());
    this._floatFrequencyData?.set(_GetEmptyFloatFrequencyData());
  }
};

// node_modules/@babylonjs/core/AudioV2/webAudio/subNodes/webAudioBaseSubGraph.js
var _WebAudioBaseSubGraph = class extends _AbstractAudioSubGraph {
  /** @internal */
  constructor(owner) {
    super();
    this._outputNode = null;
    this._owner = owner;
  }
  /** @internal */
  async initAsync(options) {
    const hasAnalyzerOptions = _HasAudioAnalyzerOptions(options);
    if (hasAnalyzerOptions) {
      await this.createAndAddSubNodeAsync(
        "Analyzer"
        /* AudioSubNode.ANALYZER */
      );
    }
    await this.createAndAddSubNodeAsync(
      "Volume"
      /* AudioSubNode.VOLUME */
    );
    await this._createSubNodePromisesResolvedAsync();
    if (hasAnalyzerOptions) {
      const analyzerNode = _GetAudioAnalyzerSubNode(this);
      if (!analyzerNode) {
        throw new Error("No analyzer subnode.");
      }
      analyzerNode.setOptions(options);
    }
    const volumeNode = _GetVolumeAudioSubNode(this);
    if (!volumeNode) {
      throw new Error("No volume subnode.");
    }
    volumeNode.setOptions(options);
    if (volumeNode.getClassName() !== "_VolumeWebAudioSubNode") {
      throw new Error("Not a WebAudio subnode.");
    }
    this._outputNode = volumeNode.node;
    if (this._outputNode && this._downstreamNodes) {
      const it = this._downstreamNodes.values();
      for (let next = it.next(); !next.done; next = it.next()) {
        const inNode = next.value._inNode;
        if (inNode) {
          this._outputNode.connect(inNode);
        }
      }
    }
  }
  /** @internal */
  get _inNode() {
    return this._outputNode;
  }
  /** @internal */
  get _outNode() {
    return this._outputNode;
  }
  // Function is async, but throws synchronously. Avoiding breaking changes.
  // eslint-disable-next-line @typescript-eslint/promise-function-async
  _createSubNode(name) {
    switch (name) {
      case "Analyzer":
        return _CreateAudioAnalyzerSubNodeAsync(this._owner.engine);
      case "Volume":
        return _CreateVolumeAudioSubNodeAsync(this._owner.engine);
      default:
        throw new Error(`Unknown subnode name: ${name}`);
    }
  }
  _onSubNodesChanged() {
    const analyzerNode = _GetAudioAnalyzerSubNode(this);
    const volumeNode = _GetVolumeAudioSubNode(this);
    if (analyzerNode && volumeNode) {
      volumeNode.connect(analyzerNode);
    }
  }
};

export {
  _FileExtensionRegex,
  _CleanUrl,
  _WebAudioParameterComponent,
  AudioNodeType,
  AbstractAudioNode,
  AbstractNamedAudioNode,
  _AbstractAudioSubNode,
  _GetVolumeAudioSubNode,
  _AudioAnalyzerDefaults,
  _HasAudioAnalyzerOptions,
  AbstractAudioAnalyzer,
  AbstractAudioOutNode,
  _WebAudioBaseSubGraph
};
//# sourceMappingURL=chunk-T26HALPL.js.map
